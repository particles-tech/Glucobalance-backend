{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11873592,"sourceType":"datasetVersion","datasetId":7427238}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\n# 1. Load sensor input data (first 50 columns)\ninputdf = pd.read_csv('/kaggle/input/diabetes-dataset/sensor_data.csv', header=None).iloc[:, :50]\n\n# 2. Assign column names\nlabels = ['white', 'red', 'ir', 'green', 'none']\nnew_columns = [f'{label}{i+1}' for label in labels for i in range(10)]\ninputdf.columns = new_columns\n\n# 3. Load and repeat output values\noutputdf = pd.read_csv('/kaggle/input/diabetes-dataset/result_diabetes2.csv', header=None)\noutputdf.columns = ['value']\n\ndef repeat_rows(df, repeat_count):\n    return df.loc[df.index.repeat(repeat_count)].reset_index(drop=True)\n\nrepeated_df = repeat_rows(outputdf, 10)\n\n# 4. Define selected features\nselected_columns = [\n    'white1', 'white2', 'white3', 'white4', 'white6', 'white7', 'white8', 'white9', 'white10',\n    'red2', 'red4', 'red6', 'red7', 'red8', 'red9', 'red10',\n    'ir1', 'ir2', 'ir4', 'ir5', 'ir6', 'ir8', 'ir9', 'ir10',\n    'green1', 'green2', 'green3', 'green5', 'green6', 'green7', 'green8', 'green9',\n    'none1', 'none2', 'none3', 'none5', 'none6', 'none7', 'none8', 'none10'\n]\n\n# 5. Define preprocessing step\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), selected_columns)\n    ],\n    remainder='drop'\n)\n\n# 6. Define pipeline with MLPRegressor\npipe = Pipeline([\n    ('preprocess', preprocessor),\n    ('model', MLPRegressor(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=42))\n])\n\n# 7. Train-test split\nX_train, X_test, y_train, y_test = train_test_split(inputdf, repeated_df, test_size=0.2, random_state=42)\n\n# 8. Fit the model\npipe.fit(X_train, y_train.values.ravel())  # Flatten y for MLPRegressor\n\n# 9. Make predictions\npredictions = pipe.predict(X_test)\n\n# 10. Evaluate\nmse = mean_squared_error(y_test, predictions)\nmae = mean_absolute_error(y_test, predictions)\nr2 = r2_score(y_test, predictions)\nepsilon = 1e-10\nmard = np.mean(np.abs((y_test.values.flatten() - predictions.flatten()) / (y_test.values.flatten() + epsilon))) * 100\n\nprint(f\"\\nEvaluation Metrics:\")\nprint(f\"Mean Squared Error (MSE): {mse:.4f}\")\nprint(f\"Mean Absolute Error (MAE): {mae:.4f}\")\nprint(f\"R-squared (R²): {r2:.4f}\")\nprint(f\"Mean Absolute Relative Difference (MARD): {mard:.2f}%\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"execution_failed":"2025-05-20T11:06:02.937Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib\njoblib.dump(pipe, 'model_pipeline.joblib')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-20T11:06:02.945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plot loss curve (training loss per epoch/iteration)\nloss_values = pipe.named_steps['model'].loss_curve_\n\nplt.figure(figsize=(8, 5))\nplt.plot(loss_values, label='Training Loss')\nplt.title('Loss Curve (MLPRegressor)')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-20T11:06:02.947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # New sensor row (reshape into a 1-row DataFrame)\n# new_input = np.array([[\n#     987, 1869, 3637, 4091, 5572, 7947, 10201, 10201, 10201, 4105,\n#     16, 14, 16, 29, 20, 96, 620, 79, 577, 110,\n#     22, 23, 23, 45, 23, 46, 25, 21, 518, 2827,\n#     4, 3, 16, 136, 80, 20, 17, 12, 194, 10,\n#     0, 0, 0, 15, 7, 1, 1, 1, 19, 0\n# ]\n\n# ])\n\n# new_input_df = pd.DataFrame(new_input, columns=new_columns)\n\n# # Predict\n# predicted_value = pipe.predict(new_input_df)[0]\n\n# print(f\"\\nPredicted Output for the Given Sensor Row: {predicted_value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T09:12:45.381433Z","iopub.execute_input":"2025-05-20T09:12:45.382290Z","iopub.status.idle":"2025-05-20T09:12:45.392951Z","shell.execute_reply.started":"2025-05-20T09:12:45.382227Z","shell.execute_reply":"2025-05-20T09:12:45.391896Z"}},"outputs":[{"name":"stdout","text":"\nPredicted Output for the Given Sensor Row: 112.2643\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# # Predict on training and testing sets\n# train_predictions = pipe.predict(X_train)\n# test_predictions = pipe.predict(X_test)\n\n# # Define a function to compute all metrics\n# def evaluate(y_true, y_pred, dataset_name=\"\"):\n#     mse = mean_squared_error(y_true, y_pred)\n#     mae = mean_absolute_error(y_true, y_pred)\n#     r2 = r2_score(y_true, y_pred)\n#     epsilon = 1e-10\n#     mard = np.mean(np.abs((y_true.flatten() - y_pred.flatten()) / (y_true.flatten() + epsilon))) * 100\n#     print(f\"\\n{dataset_name} Performance:\")\n#     print(f\"  Mean Squared Error (MSE): {mse:.4f}\")\n#     print(f\"  Mean Absolute Error (MAE): {mae:.4f}\")\n#     print(f\"  R-squared (R²): {r2:.4f}\")\n#     print(f\"  Mean Absolute Relative Difference (MARD): {mard:.2f}%\")\n\n# # Evaluate\n# evaluate(y_train.values, train_predictions, \"Training\")\n# evaluate(y_test.values, test_predictions, \"Testing\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T09:09:30.913295Z","iopub.execute_input":"2025-05-20T09:09:30.913645Z","iopub.status.idle":"2025-05-20T09:09:30.935523Z","shell.execute_reply.started":"2025-05-20T09:09:30.913620Z","shell.execute_reply":"2025-05-20T09:09:30.934590Z"}},"outputs":[{"name":"stdout","text":"\nTraining Performance:\n  Mean Squared Error (MSE): 75.1009\n  Mean Absolute Error (MAE): 5.8523\n  R-squared (R²): 0.8141\n  Mean Absolute Relative Difference (MARD): 5.36%\n\nTesting Performance:\n  Mean Squared Error (MSE): 91.5933\n  Mean Absolute Error (MAE): 6.5595\n  R-squared (R²): 0.7704\n  Mean Absolute Relative Difference (MARD): 5.92%\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# import numpy as np\n# import pandas as pd\n# from sklearn.model_selection import train_test_split\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.pipeline import Pipeline\n# from sklearn.compose import ColumnTransformer\n# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n# import tensorflow as tf\n# from tensorflow.keras import layers, models, callbacks\n\n# # 1. Load sensor input data (first 50 columns)\n# inputdf = pd.read_csv('/kaggle/input/diabetes-dataset/sensor_data.csv', header=None).iloc[:, :50]\n\n# # 2. Assign column names\n# labels = ['white', 'red', 'ir', 'green', 'none']\n# new_columns = [f'{label}{i+1}' for label in labels for i in range(10)]\n# inputdf.columns = new_columns\n\n# # 3. Load and repeat output values\n# outputdf = pd.read_csv('/kaggle/input/diabetes-dataset/result_diabetes2.csv', header=None)\n# outputdf.columns = ['value']\n\n# def repeat_rows(df, repeat_count):\n#     return df.loc[df.index.repeat(repeat_count)].reset_index(drop=True)\n\n# repeated_df = repeat_rows(outputdf, 10)\n\n# # 4. Define selected features\n# selected_columns = [\n#     'white1', 'white2', 'white3', 'white4', 'white6', 'white7', 'white8', 'white9', 'white10',\n#     'red2', 'red4', 'red6', 'red7', 'red8', 'red9', 'red10',\n#     'ir1', 'ir2', 'ir4', 'ir5', 'ir6', 'ir8', 'ir9', 'ir10',\n#     'green1', 'green2', 'green3', 'green5', 'green6', 'green7', 'green8', 'green9',\n#     'none1', 'none2', 'none3', 'none5', 'none6', 'none7', 'none8', 'none10'\n# ]\n\n# # 5. Preprocessing using sklearn\n# scaler = StandardScaler()\n# inputdf_scaled = inputdf.copy()\n# inputdf_scaled[selected_columns] = scaler.fit_transform(inputdf[selected_columns])\n\n# # 6. Train-test split\n# X_train, X_test, y_train, y_test = train_test_split(inputdf_scaled[selected_columns], repeated_df['value'], test_size=0.2, random_state=42)\n\n# # 7. Define TensorFlow model\n# def build_model(input_dim):\n#     model = models.Sequential([\n#         layers.Input(shape=(input_dim,)),\n#         layers.Dense(64, activation='relu'),\n#         layers.Dense(32, activation='relu'),\n#         layers.Dense(1)  # Output layer for regression\n#     ])\n#     model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n#     return model\n\n# model = build_model(input_dim=len(selected_columns))\n\n# # 8. Train the model\n# early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n\n# history = model.fit(\n#     X_train, y_train,\n#     validation_split=0.1,\n#     epochs=500,\n#     batch_size=32,\n#     callbacks=[early_stop],\n#     verbose=1\n# )\n\n# # 9. Make predictions\n# predictions = model.predict(X_test).flatten()\n\n# # 10. Evaluate\n# mse = mean_squared_error(y_test, predictions)\n# mae = mean_absolute_error(y_test, predictions)\n# r2 = r2_score(y_test, predictions)\n# epsilon = 1e-10\n# mard = np.mean(np.abs((y_test.values.flatten() - predictions.flatten()) / (y_test.values.flatten() + epsilon))) * 100\n\n# print(f\"\\nEvaluation Metrics:\")\n# print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n# print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n# print(f\"R-squared (R²): {r2:.4f}\")\n# print(f\"Mean Absolute Relative Difference (MARD): {mard:.2f}%\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-20T11:06:02.922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}